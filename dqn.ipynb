{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Implementation without HER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For comments and explanations please see [dqn-her.ipynb](dqn-her.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "# is_ipython = 'inline' in matplotlib.get_backend()\n",
    "# if is_ipython:\n",
    "#     from IPython import display\n",
    "\n",
    "# plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit flipping environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitFlipEnv():\n",
    "    \n",
    "    def __init__(self, n = 8):\n",
    "        self.n = n\n",
    "        self.init_state = torch.randint(2, size=(n,))\n",
    "        self.target_state = torch.randint(2, size=(n,))\n",
    "        while np.array_equal(self.init_state, self.target_state):\n",
    "            self.target_state = torch.randint(2, size=(n,))\n",
    "        self.curr_state = self.init_state.clone()\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.curr_state[action] = 1 - self.curr_state[action]\n",
    "        if np.array_equal(self.curr_state, self.target_state):\n",
    "            return self.curr_state.clone(), 0\n",
    "        else:\n",
    "            return self.curr_state.clone(), -1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.init_state = torch.randint(2, size=(self.n,))\n",
    "        self.target_state = torch.randint(2, size=(self.n,))\n",
    "        while np.array_equal(self.init_state, self.target_state):\n",
    "            self.target_state = torch.randint(2, size=(self.n,))\n",
    "        self.curr_state = self.init_state.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', \n",
    "                       ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition which should contain:\n",
    "        - current state\n",
    "        - action taken\n",
    "        - next state\n",
    "        - reward obtained\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "        if len(self.memory) > self.capacity:\n",
    "            print('!!!!!memory capacity exceeded!')\n",
    "            del self.memory[0]\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns batch_size number of samples from the replay memory\n",
    "        \"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS = 8\n",
    "HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.ln1 = nn.Linear(NUM_BITS, HIDDEN_SIZE)\n",
    "        self.ln2 = nn.Linear(HIDDEN_SIZE, NUM_BITS)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "\n",
    "TARGET_UPDATE = 200\n",
    "MODEL_PATH = '_dqn_policy_net.pt'\n",
    "WEIGHTS_PATH = '_dqn_policy_net_weights.pt'\n",
    "FIGURE_PATH = '_dqn.png'\n",
    "SAVE_MODEL = True\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = FNN().to(device)\n",
    "target_net = FNN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, greedy=False):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if greedy:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state.float()).argmax().view(1,1)\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state.float()).argmax().view(1,1)\n",
    "    else: \n",
    "        return torch.tensor([[random.randrange(NUM_BITS)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    \n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, \n",
    "                                           batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state \n",
    "                                      if s is not None])\n",
    "    \n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    state_action_values = policy_net(state_batch.float()).gather(1, action_batch)\n",
    "    \n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states.float()).max(1)[0].detach()\n",
    "    \n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.float()\n",
    "    \n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Long for argument #2 'mat1' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-741ea1c62e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepisode_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-8ab0b24a8036>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnext_state_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mnext_state_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_final_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_final_next_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mexpected_state_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_state_values\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorforce/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-a9188910543b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorforce/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorforce/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorforce/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "CHECK_RATE = 500\n",
    "num_episodes = 30000\n",
    "EPS_DECAY = num_episodes * NUM_BITS * 0.25\n",
    "env = BitFlipEnv(NUM_BITS)\n",
    "success = 0\n",
    "episodes = []\n",
    "success_rate = []\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    state = env.init_state\n",
    "    goal = env.target_state\n",
    "    transitions = []\n",
    "    episode_success = False\n",
    "    for t in range(NUM_BITS):\n",
    "        if episode_success:\n",
    "            continue\n",
    "        action = select_action(state)\n",
    "        next_state, reward = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        optimize_model()\n",
    "        if reward == 0:\n",
    "            if episode_success:\n",
    "                continue\n",
    "            else:\n",
    "                episode_success = True\n",
    "                success += 1\n",
    "        \n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "#         print(i_episode, end=' ')\n",
    "    if i_episode % CHECK_RATE == 0:\n",
    "        print('success rate for last {} episodes after {} episodes of training: {}%'.format(CHECK_RATE, i_episode, success/CHECK_RATE * 100))\n",
    "        success_rate.append(success/CHECK_RATE)\n",
    "        episodes.append(i_episode)\n",
    "        success = 0\n",
    "\n",
    "episodes.append(num_episodes)\n",
    "success_rate.append(success/CHECK_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.plot(episodes, success_rate)\n",
    "plt.title('DQN (without HER) performance on N={} bits'.format(NUM_BITS))\n",
    "plt.ylabel('Success Rate')\n",
    "plt.xlabel('Number of Episodes')\n",
    "plt.ylim([0, 1])\n",
    "if SAVE_MODEL:\n",
    "    plt.savefig(str(NUM_BITS)+FIGURE_PATH)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved\n",
      "Model saved\n",
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiyou/anaconda3/envs/tensorforce/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/leiyou/anaconda3/envs/tensorforce/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "if SAVE_MODEL:\n",
    "    torch.save(policy_net.state_dict(), str(NUM_BITS)+WEIGHTS_PATH)\n",
    "    print('Weights saved')\n",
    "    torch.save(policy_net, str(NUM_BITS)+MODEL_PATH)\n",
    "    print('Model saved')\n",
    "\n",
    "print('Complete')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "successes = 0\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    test_state = env.init_state\n",
    "    goal_state = env.target_state\n",
    "#     print('#############################################')\n",
    "#     print('start', test_state)\n",
    "#     print('goal', goal_state)\n",
    "    next_state = test_state.clone()\n",
    "    for i in range(NUM_BITS):\n",
    "        action = select_action(next_state, greedy=True)\n",
    "        next_state, reward = env.step(action.item())\n",
    "#         print('taking action', action)\n",
    "#         print('next state', next_state)\n",
    "        if np.array_equal(next_state, goal_state):\n",
    "            successes += 1\n",
    "            break\n",
    "print(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
